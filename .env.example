# Ollama Configuration
OLLAMA_MODEL=codellama:7b
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_NUM_PREDICT=12000

# Embedding Configuration
USE_LOCAL_EMBEDDINGS=true
EMBEDDING_MODEL=all-MiniLM-L6-v2

# OpenAI Configuration (Optional - for cloud-based embeddings or LLM)
# OPENAI_API_KEY=your_openai_api_key_here

# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=True

# RAG System Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_SOURCES=5
SIMILARITY_TOP_K=4

# Logging
LOG_LEVEL=INFO